{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "a. import the package needed & define the deivce used"
      ],
      "metadata": {
        "id": "zMcteopR8x7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H0BMGlGc7ttj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. mounting the drive"
      ],
      "metadata": {
        "id": "0qiaLzjp86We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL6kjDFo7y2l",
        "outputId": "8ebde807-e6a7-4813-a8c6-744a90bd72cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c.open file & train the sentence piece encoder"
      ],
      "metadata": {
        "id": "_wPLGMqc8-ds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/files/dataset.txt\" , \"r\" , encoding=\"utf-8\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "import sentencepiece as spm\n",
        "spm.SentencePieceTrainer.train(input='/content/drive/MyDrive/files/dataset.txt', model_prefix='m', vocab_size=3000) #setting vocab to higher value to encode sub words\n",
        "sp = spm.SentencePieceProcessor(model_file='/content/m.model')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o7L6MHSh70gv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Load the dataset and encode it"
      ],
      "metadata": {
        "id": "CeXuE1Yh9RSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/files/dataset.csv\")\n",
        "df.columns=[\"question\" , \"answer\"]"
      ],
      "metadata": {
        "id": "_rtKmXDA8oZU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data():\n",
        "  x = [torch.tensor(sp.encode(i)) for i in df[\"question\"]]\n",
        "  y = [torch.tensor(sp.encode(i)) for i in df[\"answer\"]]\n",
        "  padding_x  = pad_sequence(x , batch_first=True , padding_value=0)\n",
        "  padding_y  = pad_sequence(y , batch_first=True , padding_value=0)\n",
        "\n",
        "  desired_padding = padding_x.size(1) - padding_y.size(1)\n",
        "  padding_y =  F.pad(padding_y , (0, desired_padding), value=0)\n",
        "  return padding_x , padding_y\n",
        "\n",
        "X,Y = encode_data()"
      ],
      "metadata": {
        "id": "nrM4TydM997e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the decoders"
      ],
      "metadata": {
        "id": "iv4McH4-szYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    # q: 30 x 8 x 200 x 64, k: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64, mask 200 x 200\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k) # 30 x 8 x 200 x 200\n",
        "    print(f\"scaled.size() : {scaled.size()}\")\n",
        "    if mask is not None:\n",
        "        print(f\"-- ADDING MASK of shape {mask.size()} --\")\n",
        "        scaled += mask # 30 x 8 x 200 x 200\n",
        "    attention = F.softmax(scaled, dim=-1) # 30 x 8 x 200 x 200\n",
        "    values = torch.matmul(attention, v) # 30 x 8 x 200 x 64\n",
        "    return values, attention\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  x: 30 x 200 x 512\n",
        "        x = self.linear1(x) #30 x 200 x 2048\n",
        "        print(f\"x after first linear layer: {x.size()}\")\n",
        "        x = self.relu(x) #30 x 200 x 2048\n",
        "        print(f\"x after relu layer: {x.size()}\")\n",
        "        x = self.dropout(x) #30 x 200 x 2048\n",
        "        print(f\"x after dropout layer: {x.size()}\")\n",
        "        x = self.linear2(x) #30 x 200 x 512\n",
        "        print(f\"x after 2nd linear layer: {x.size()}\")\n",
        "        return x #30 x 200 x 512\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape)) # 512\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape)) # 512\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs : 30 x 200 x 512\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))] # [-1]\n",
        "        print(f\"dims: {dims}\")\n",
        "        mean = inputs.mean(dim=dims, keepdim=True) #30 x 200 x 1\n",
        "        print(f\"Mean ({mean.size()})\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True) # 30 x 200 x 512\n",
        "        std = (var + self.eps).sqrt() # 30 x 200 x 512\n",
        "        print(f\"Standard Deviation  ({std.size()})\")\n",
        "        y = (inputs - mean) / std # 30 x 200 x 512\n",
        "        print(f\"y: {y.size()}\")\n",
        "        out = self.gamma * y  + self.beta  # 30 x 200 x 512\n",
        "        print(f\"out: {out.size()}\")\n",
        "        return out\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model) # 1024\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size() # 30 x 200 x 512\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        kv = self.kv_layer(x) # 30 x 200 x 1024\n",
        "        print(f\"kv.size(): {kv.size()}\")\n",
        "        q = self.q_layer(y) # 30 x 200 x 512\n",
        "        print(f\"q.size(): {q.size()}\")\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)  # 30 x 200 x 8 x 128\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)  # 30 x 200 x 8 x 64\n",
        "        kv = kv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 128\n",
        "        q = q.permute(0, 2, 1, 3) # 30 x 8 x 200 x 64\n",
        "        k, v = kv.chunk(2, dim=-1) # K: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) #  30 x 8 x 200 x 64\n",
        "        print(f\"values: {values.size()}, attention:{attention.size()}\")\n",
        "        values = values.reshape(batch_size, sequence_length, d_model) #  30 x 200 x 512\n",
        "        out = self.linear_layer(values)  #  30 x 200 x 512\n",
        "        print(f\"out after passing through linear layer: {out.size()}\")\n",
        "        return out  #  30 x 200 x 512\n",
        "\n",
        "#key diffrence between both is that this one will take the KV from the encoder and the Q from the generated (aka logits)\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model) # 1536\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size() # 30 x 200 x 512\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x) # 30 x 200 x 1536\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim) # 30 x 200 x 8 x 192\n",
        "        print(f\"qkv after reshape .size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 192\n",
        "        print(f\"qkv after permutation: {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1) # q: 30 x 8 x 200 x 64, k: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "        print(f\"q: {q.size()}, k:{k.size()}, v:{v.size()}\")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) # values: 30 x 8 x 200 x 64\n",
        "        print(f\"values: {values.size()}, attention:{attention.size()}\")\n",
        "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim) # 30 x 200 x 512\n",
        "        print(f\"values after reshaping: {values.size()}\")\n",
        "        out = self.linear_layer(values) # 30 x 200 x 512\n",
        "        print(f\"out after passing through linear layer: {out.size()}\")\n",
        "        return out # 30 x 200 x 512\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self , d_model , ffn_hidden , num_heads , drop_prob):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "    self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "    self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "    self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "    self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "    self.norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "    self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "  def forward(self , x, y , decoder_mask):\n",
        "    _y = y # expected output\n",
        "    y = self.self_attention(y,mask=decoder_mask) #masking\n",
        "    y = self.dropout1(y)\n",
        "    y = self.norm1(y+ _y) #residual connection\n",
        "\n",
        "    _y = y\n",
        "    y = self.encoder_decoder_attention(x,y,mask=None)\n",
        "    y = self.dropout2(y)\n",
        "    y= self.norm2(y+_y)\n",
        "\n",
        "    _y = y\n",
        "    y = self.ffn(y)\n",
        "    y = self.dropout3(y)\n",
        "    y = self.norm3(y+_y)\n",
        "\n",
        "    return y\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "  def forward(self , *inputs):\n",
        "    x,y,mask = inputs\n",
        "    for module in self._modules.values(): #calling every decoder layer\n",
        "      y = module(x,y,mask) #keep fiding th layers with the past generated text\n",
        "    return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self , d_model ,ffn_hidden , num_heads , drop_prob , num_layers=1):\n",
        "    super().__init__()\n",
        "    self.layers = SequentialDecoder(*[DecoderLayer(d_model , ffn_hidden , num_heads , drop_prob) for _ in range(num_layers)])\n",
        "  def forward(self , x , y , mask):\n",
        "    y = self.layers(x,y,mask)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "cZLr-mNJsyn5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Variable Initialization"
      ],
      "metadata": {
        "id": "aK8Qr5YJOO8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30 #number of inputs processed in the same time\n",
        "d_model = 512 # size of the embeddings for example each token represented with 64 embedding\n",
        "num_heads = 8 # number of heads that works in parallel in multi headed\n",
        "num_layers = 5\n",
        "drop_prob = 0.1\n",
        "max_sequance = 200\n",
        "ffn_hidden = 2048\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# let's go for a basic test\n",
        "x = torch.randn( (batch_size, max_sequance, d_model) )\n",
        "y = torch.randn( (batch_size, max_sequance, d_model) )\n",
        "mask = torch.full([max_sequance , max_sequance] , float(\"-inf\"))\n",
        "mask = torch.triu(mask , diagonal=1)\n",
        "decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "out = decoder(x,y,mask)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7Vgioi-OXLT",
        "outputId": "db0e447a-fab0-41fb-b393-a705d1ed5222"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
              "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
              "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
              "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. Generate Batch"
      ],
      "metadata": {
        "id": "-d_o1UpNS3MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = X[:-100]\n",
        "validX = X[-100:]\n",
        "trainY  =Y[:-100]\n",
        "validY = Y[-100:]\n",
        "position = 0\n",
        "def get_batch(split):\n",
        "  if split == \"train\":\n",
        "    x = torch.stack([trainX[i] for i in range(position,position+batch_size)])\n",
        "    y =  torch.stack([trainY[i] for i in range(position,position+batch_size)])\n",
        "  else :\n",
        "    ix = torch.randint(100, (batch_size,))\n",
        "    x = torch.stack([validX[i] for i in ix])\n",
        "    y =  torch.stack([validY[i] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x , y\n",
        "\n",
        "get_batch(\"train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6lDXl_OS5bt",
        "outputId": "fec1193a-382f-4e13-a2c4-37d7f2344ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[119,  10,  25,  ...,   0,   0,   0],\n",
              "         [ 61,  12,   7,  ...,   0,   0,   0],\n",
              "         [ 25,  10, 561,  ...,   0,   0,   0],\n",
              "         [ 61,   3,  21,  ...,   0,   0,   0]], device='cuda:0'),\n",
              " tensor([[ 481, 1563,  124,  ...,    0,    0,    0],\n",
              "         [  47,   12,   70,  ...,    0,    0,    0],\n",
              "         [ 380,  128,    8,  ...,    0,    0,    0],\n",
              "         [  50,  177,  600,  ...,    0,    0,    0]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "g. Transformer Modules"
      ],
      "metadata": {
        "id": "xDhJS9LLOKBM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DtI1JTbYwWMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "h. Testing"
      ],
      "metadata": {
        "id": "hLfUg5D_wUB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"hello how you doing ?\"\n",
        "converted = [sp.encode(context)]\n",
        "converted = torch.tensor(converted , device=device)\n",
        "converted =  F.pad(converted , (0, 307 - len(converted) ), value=0)\n",
        "print(converted)\n",
        "print(sp.decode(m.generate(converted, max_number_tokens=20)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yztrZwCAkvlv",
        "outputId": "bb97945e-13f9-424a-a804-6e3d8c4b7620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[107,  48, 103, 124,  10, 338,   3,  11,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "           0,   0,   0,   0,   0,   0]], device='cuda:0')\n",
            "hello how you doing ? ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ \n"
          ]
        }
      ]
    }
  ]
}